{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings=['utf-8','latin-1','ISO-8859-1','cp1252','ascii','utf-16','utf-32']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52629</td>\n",
       "      <td>- l'expérience des migrant·es avec @AntoineRob...</td>\n",
       "      <td>Sun Dec 18 10:00:43 +0000 2022</td>\n",
       "      <td>1.120000e+18</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52448</td>\n",
       "      <td>\"Bonnes vacances avec les enfants ! Gros bisou...</td>\n",
       "      <td>Sun Dec 18 10:05:00 +0000 2022</td>\n",
       "      <td>4.146315e+08</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53081</td>\n",
       "      <td>\"Chanter\" tu ne prie pas... un gros NTM SALE P...</td>\n",
       "      <td>Sun Dec 18 09:50:47 +0000 2022</td>\n",
       "      <td>1.550000e+18</td>\n",
       "      <td>Hate_Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53682</td>\n",
       "      <td>\"Elle dit qu'il y a des place vacantes,quand o...</td>\n",
       "      <td>Sun Dec 18 09:37:21 +0000 2022</td>\n",
       "      <td>8.470000e+17</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52605</td>\n",
       "      <td>\"Tout niquer\". c'est classique chez un adolesc...</td>\n",
       "      <td>Sun Dec 18 10:01:20 +0000 2022</td>\n",
       "      <td>9.330000e+17</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text  \\\n",
       "0  52629  - l'expérience des migrant·es avec @AntoineRob...   \n",
       "1  52448  \"Bonnes vacances avec les enfants ! Gros bisou...   \n",
       "2  53081  \"Chanter\" tu ne prie pas... un gros NTM SALE P...   \n",
       "3  53682  \"Elle dit qu'il y a des place vacantes,quand o...   \n",
       "4  52605  \"Tout niquer\". c'est classique chez un adolesc...   \n",
       "\n",
       "                       created_at       user_id        Label  \n",
       "0  Sun Dec 18 10:00:43 +0000 2022  1.120000e+18         None  \n",
       "1  Sun Dec 18 10:05:00 +0000 2022  4.146315e+08         None  \n",
       "2  Sun Dec 18 09:50:47 +0000 2022  1.550000e+18  Hate_Speech  \n",
       "3  Sun Dec 18 09:37:21 +0000 2022  8.470000e+17         None  \n",
       "4  Sun Dec 18 10:01:20 +0000 2022  9.330000e+17         None  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df=pd.read_csv(\"./src/data/annotated_data/Twitter_Annotated/Twitter_data_annotated_Lamia.csv\")\n",
    "df=tweet_df.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2241 entries, 0 to 2240\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   id          2241 non-null   int64  \n",
      " 1   text        2241 non-null   object \n",
      " 2   created_at  2241 non-null   object \n",
      " 3   user_id     2241 non-null   float64\n",
      " 4   Label       2241 non-null   object \n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 87.7+ KB\n"
     ]
    }
   ],
   "source": [
    "#EDA on the data\n",
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess the \"text\" column\n",
    "\n",
    "def preprocess_usernames():\n",
    "    #new column \"usernames\" to store the usernames\n",
    "    df['usernames'] = df['text'].apply(lambda x: re.findall(r'@(\\w+)', x))\n",
    "    for i in range(len(df)):\n",
    "        if len(df[\"usernames\"][i]) > 0:\n",
    "            df[\"usernames\"][i] = df[\"usernames\"][i][0]\n",
    "        else:\n",
    "            df[\"usernames\"][i] = None\n",
    "\n",
    "    #remove the usernames\n",
    "    df['text'] = df['text'].apply(lambda x: re.sub(r'@(\\w+)', '', x))\n",
    "\n",
    "\n",
    "preprocess_usernames()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_urls():\n",
    "    #new column \"urls\" to store the urls\n",
    "    df['urls'] = df['text'].apply(lambda x: re.findall(r'http\\S+', x))\n",
    "    for i in range(len(df)):\n",
    "        if len(df[\"urls\"][i]) > 0:\n",
    "            df[\"urls\"][i] = df[\"urls\"][i][0]\n",
    "        else:\n",
    "            df[\"urls\"][i] = None\n",
    "\n",
    "    #remove the urls\n",
    "    df['text'] = df['text'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
    "\n",
    "\n",
    "preprocess_urls()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_hashtags():\n",
    "    #new column \"hashtags\" to store the hashtags\n",
    "    df['hashtags'] = df['text'].apply(lambda x: re.findall(r'#(\\w+)', x))\n",
    "    for i in range(len(df)):\n",
    "        if len(df[\"hashtags\"][i]) > 0:\n",
    "            df[\"hashtags\"][i] = df[\"hashtags\"][i][0]\n",
    "        else:\n",
    "            df[\"hashtags\"][i] = None\n",
    "\n",
    "    #remove the hashtags\n",
    "    df['text'] = df['text'].apply(lambda x: re.sub(r'#(\\w+)', '', x))\n",
    "\n",
    "preprocess_hashtags()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove characters with different encodings \n",
    "df['text'] = df['text'].apply(lambda x: re.sub(r'[^\\x00-\\x7F]+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new column \"Day\" to store the names of the day of the tweet\n",
    "df[\"Day\"]=df[\"created_at\"].apply(lambda x: x.split(\" \")[0])\n",
    "\n",
    "#convet to datetime format\n",
    "df[\"created_at\"] = pd.to_datetime(df[\"created_at\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sepate the date and time\n",
    "df[\"Date\"]=df[\"created_at\"].apply(lambda x: x.date())   \n",
    "df[\"Time\"]=df[\"created_at\"].apply(lambda x: x.time())\n",
    "\n",
    "#remove the \"created_at\" column\n",
    "df.drop(\"created_at\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #count stopword in each tweet\n",
    "# import pprint\n",
    "# stop=[]\n",
    "# for i in range(len(df)):\n",
    "#     stop.append((f\"tweet {i} has\",len([word for word in df[\"text\"][i].split() if word in stopwords.words('french')])))\n",
    "# # pprint.pprint(stop)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove special characters\n",
    "# df['text'] = df['text'].apply(lambda x: re.sub(r'[^a-zA-Z0-9]', ' ', x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"text\"].apply(lambda x: re.findall(f'@(\\w+)', x)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>Label</th>\n",
       "      <th>usernames</th>\n",
       "      <th>urls</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>Day</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52629</td>\n",
       "      <td>- l'exprience des migrantes avec \\n</td>\n",
       "      <td>1.120000e+18</td>\n",
       "      <td>None</td>\n",
       "      <td>AntoineRoblain</td>\n",
       "      <td>https://t.co/x3KSTzppuj</td>\n",
       "      <td>None</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2022-12-18</td>\n",
       "      <td>10:00:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52448</td>\n",
       "      <td>\"Bonnes vacances avec les enfants ! Gros bisous\"</td>\n",
       "      <td>4.146315e+08</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://t.co/5a9vADRtNQ</td>\n",
       "      <td>None</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2022-12-18</td>\n",
       "      <td>10:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53081</td>\n",
       "      <td>\"Chanter\" tu ne prie pas... un gros NTM SALE P...</td>\n",
       "      <td>1.550000e+18</td>\n",
       "      <td>Hate_Speech</td>\n",
       "      <td>None</td>\n",
       "      <td>https://t.co/1wv7ZotG8y</td>\n",
       "      <td>None</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2022-12-18</td>\n",
       "      <td>09:50:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53682</td>\n",
       "      <td>\"Elle dit qu'il y a des place vacantes,quand o...</td>\n",
       "      <td>8.470000e+17</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://t.co/oGeVRu7q7U</td>\n",
       "      <td>None</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2022-12-18</td>\n",
       "      <td>09:37:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52605</td>\n",
       "      <td>\"Tout niquer\". c'est classique chez un adolesc...</td>\n",
       "      <td>9.330000e+17</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://t.co/AjXyUUhL3p</td>\n",
       "      <td>None</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2022-12-18</td>\n",
       "      <td>10:01:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text       user_id  \\\n",
       "0  52629                - l'exprience des migrantes avec \\n  1.120000e+18   \n",
       "1  52448  \"Bonnes vacances avec les enfants ! Gros bisous\"   4.146315e+08   \n",
       "2  53081  \"Chanter\" tu ne prie pas... un gros NTM SALE P...  1.550000e+18   \n",
       "3  53682  \"Elle dit qu'il y a des place vacantes,quand o...  8.470000e+17   \n",
       "4  52605  \"Tout niquer\". c'est classique chez un adolesc...  9.330000e+17   \n",
       "\n",
       "         Label       usernames                     urls hashtags  Day  \\\n",
       "0         None  AntoineRoblain  https://t.co/x3KSTzppuj     None  Sun   \n",
       "1         None            None  https://t.co/5a9vADRtNQ     None  Sun   \n",
       "2  Hate_Speech            None  https://t.co/1wv7ZotG8y     None  Sun   \n",
       "3         None            None  https://t.co/oGeVRu7q7U     None  Sun   \n",
       "4         None            None  https://t.co/AjXyUUhL3p     None  Sun   \n",
       "\n",
       "         Date      Time  \n",
       "0  2022-12-18  10:00:43  \n",
       "1  2022-12-18  10:05:00  \n",
       "2  2022-12-18  09:50:47  \n",
       "3  2022-12-18  09:37:21  \n",
       "4  2022-12-18  10:01:20  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpProjects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6eca8220bf33cf72c8f6cb1234053b7178b904807069b3c506f7f7ef4ca9025a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
